"""
Generate Notebook Node
======================
Creates the final Colab notebook with all discovered information.

Note: Service tokens (GitHub, Slack, etc.) are NOT entered in the notebook.
User sets those up later in the downloaded agent's .env file.
Notebook only requires LLM API key for training data generation.
"""

import json
from meta_agent.state import MetaAgentState


def create_notebook_cell(cell_type: str, source: list[str], execution_count: int = None) -> dict:
    """Create a Jupyter notebook cell."""
    cell = {
        "cell_type": cell_type,
        "metadata": {},
        "source": source,
    }
    if cell_type == "code":
        cell["execution_count"] = execution_count
        cell["outputs"] = []
    return cell


def generate_notebook(state: MetaAgentState) -> dict:
    """
    Generate the complete Colab notebook.
    
    Notebook includes:
    1. Title and description
    2. Installation cell
    3. LLM API key configuration (only!)
    4. Tool schemas cell
    5. MCP server configs cell
    6. Build cell
    7. Export/download cell
    
    Note: No service tokens needed in notebook - user sets those
    in the downloaded agent's .env file.
    
    Args:
        state: Current MetaAgentState
        
    Returns:
        State update with colab_notebook JSON string
    """
    problem_statement = state.get("problem_statement", "")
    
    # Use FILTERED results
    mcp_servers = state.get("filtered_mcp_servers") or state.get("mcp_servers", [])
    api_servers = state.get("filtered_api_servers") or state.get("api_servers", [])
    tool_schemas = state.get("filtered_tool_schemas") or state.get("filtered_tools") or state.get("tool_schemas", [])
    
    # Get skill (for guided data generation)
    full_skill = state.get("full_skill", "")
    condensed_rules = state.get("condensed_rules", "")
    
    print("\nüìì Generating Colab notebook...")
    
    cells = []
    
    # ==========================================================================
    # Cell 1: Title and Introduction
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "# üöÄ OnsetLab Agent Builder\n",
        "\n",
        "This notebook was auto-generated by the OnsetLab Meta-Agent.\n",
        "\n",
        f"**Problem Statement:** {problem_statement}\n",
        "\n",
        "## What this notebook does:\n",
        f"1. Configures **{len(mcp_servers)}** MCP servers\n",
        f"2. Registers **{len(tool_schemas)}** tools\n",
        "3. Generates synthetic training data\n",
        "4. Fine-tunes a small language model (~15 min)\n",
        "5. Packages your agent for local deployment\n",
        "\n",
        "---"
    ]))
    
    # ==========================================================================
    # Cell 2: Installation
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 1Ô∏è‚É£ Install Dependencies\n",
        "\n",
        "First, check GPU and install all required dependencies:"
    ]))
    
    cells.append(create_notebook_cell("code", [
        "# Check GPU\n",
        "!nvidia-smi --query-gpu=name --format=csv,noheader\n",
        "\n",
        "# Install Unsloth (Colab-optimized) for efficient LoRA training\n",
        '!pip install -q "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"\n',
        "\n",
        "# Install training dependencies (--no-deps to avoid version conflicts)\n",
        "!pip install -q --no-deps xformers trl peft accelerate bitsandbytes\n",
        "\n",
        "# Install data generation dependencies\n",
        "!pip install -q openai anthropic httpx\n",
        "\n",
        "print('‚úÖ All dependencies installed!')"
    ]))
    
    # ==========================================================================
    # Cell 3: LLM API Key Configuration (ONLY)
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 2Ô∏è‚É£ Enter Your LLM API Key\n",
        "\n",
        "You need an API key to generate training data. Choose **one**:\n",
        "\n",
        "- **Anthropic (Recommended)**: https://console.anthropic.com/\n",
        "- **OpenAI**: https://platform.openai.com/api-keys\n",
        "\n",
        "> **Note:** Service tokens (GitHub, Slack, etc.) are configured later\n",
        "> when you run the agent locally. You don't need them here!"
    ]))
    
    cells.append(create_notebook_cell("code", [
        "import os\n",
        "\n",
        "# Enter ONE of these API keys for training data generation:\n",
        "\n",
        "# Option 1: Anthropic (claude-sonnet) - RECOMMENDED\n",
        "os.environ['ANTHROPIC_API_KEY'] = ''  # @param {type:\"string\"}\n",
        "\n",
        "# Option 2: OpenAI (gpt-4o)\n",
        "os.environ['OPENAI_API_KEY'] = ''  # @param {type:\"string\"}\n",
        "\n",
        "# Verify\n",
        "if os.environ.get('ANTHROPIC_API_KEY') or os.environ.get('OPENAI_API_KEY'):\n",
        "    print('‚úÖ API key configured!')\n",
        "else:\n",
        "    print('‚ö†Ô∏è Please enter an API key above')"
    ]))
    
    # ==========================================================================
    # Cell 4: Tool Schemas (collapsible)
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        f"## 3Ô∏è‚É£ Tool Schemas ({len(tool_schemas)} tools)\n",
        "\n",
        "The code cell below defines all tool schemas. **Click to expand if needed.**"
    ]))
    
    # Format tool schemas as Python code - collapsible in Colab
    tools_code = [
        f"#@title üì¶ Tool Schemas ({len(tool_schemas)} tools) - Click to expand\n",
        "from onsetlab import ToolSchema\n",
        "\n",
        "tools = [\n",
    ]
    
    for tool in tool_schemas:
        tools_code.append(f"    ToolSchema(\n")
        tools_code.append(f"        name=\"{tool.get('name', 'unknown')}\",\n")
        
        # Escape description
        desc = tool.get('description', '').replace('"', '\\"').replace('\n', ' ')[:100]
        tools_code.append(f"        description=\"{desc}\",\n")
        
        # Parameters - clean up format for ToolSchema
        # Remove 'required' from inside each param (it belongs in required_params)
        # Also simplify to just type + description (remove enum, default, etc. for cleaner output)
        raw_params = tool.get('parameters', tool.get('inputSchema', {}).get('properties', {}))
        clean_params = {}
        for param_name, param_def in raw_params.items():
            # Keep only essential fields: type and description
            clean_param = {
                'type': param_def.get('type', 'string'),
                'description': param_def.get('description', '')[:80],  # Truncate long descriptions
            }
            clean_params[param_name] = clean_param
        
        if clean_params:
            # Use repr() to get Python syntax (True instead of true)
            params_str = repr(clean_params)
            tools_code.append(f"        parameters={params_str},\n")
        else:
            tools_code.append(f"        parameters={{}},\n")
        
        required = tool.get('required_params', tool.get('inputSchema', {}).get('required', []))
        tools_code.append(f"        required_params={required},\n")
        tools_code.append(f"    ),\n")
    
    tools_code.append("]\n")
    tools_code.append(f"\nprint(f'‚úÖ Loaded {{len(tools)}} tools')")
    
    cells.append(create_notebook_cell("code", tools_code))
    
    # ==========================================================================
    # Cell 5: Server Configs (collapsible)
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        f"## 4Ô∏è‚É£ MCP Server Configurations ({len(mcp_servers)} servers)\n",
        "\n",
        "Server configs for your agent. **Click to expand if needed.**"
    ]))
    
    servers_code = [
        f"#@title üîß MCP Servers ({len(mcp_servers)}) - Click to expand\n",
        "from onsetlab import MCPServerConfig\n",
        "\n",
        "mcp_servers = [\n",
    ]
    
    # Get filtered tool names by service for matching
    filtered_tool_names = {t.get("name") for t in tool_schemas}
    
    for server in mcp_servers:
        service = server.get("service") or server.get("service_id") or server.get("name", "unknown").lower()
        package = server.get("package", {})
        auth = server.get("auth", {})
        
        # Get package name based on type
        if isinstance(package, dict):
            pkg_type = package.get("type", "npm")
            if pkg_type == "docker":
                pkg_name = package.get("image", "")
            elif pkg_type == "binary":
                # For binary, use github_repo or command
                pkg_name = package.get("github_repo") or package.get("command", "")
            else:
                # npm package
                pkg_name = package.get("name", "")
        else:
            pkg_name = str(package)
        
        servers_code.append(f"    MCPServerConfig(\n")
        servers_code.append(f"        package=\"{pkg_name}\",\n")
        
        # Server type
        server_type = package.get("type", "npm") if isinstance(package, dict) else "npm"
        if server_type != "npm":
            servers_code.append(f"        server_type=\"{server_type}\",\n")
        
        # Docker-specific: add docker_image
        if server_type == "docker" and isinstance(package, dict):
            docker_image = package.get("image", "")
            if docker_image:
                servers_code.append(f"        docker_image=\"{docker_image}\",\n")
        
        # Binary-specific: add command and args
        if server_type == "binary" and isinstance(package, dict):
            binary_cmd = package.get("command", "")
            binary_args = package.get("args", [])
            if binary_cmd:
                servers_code.append(f"        command=\"{binary_cmd}\",\n")
            if binary_args:
                args_str = ", ".join(f'"{arg}"' for arg in binary_args)
                servers_code.append(f"        args=[{args_str}],\n")
        
        # Auth type
        auth_type = auth.get("type", "none")
        servers_code.append(f"        auth_type=\"{auth_type}\",\n")
        
        # Env vars
        env_vars = auth.get("env_vars", [])
        if env_vars:
            env_vars_str = ", ".join(f'"{ev}"' for ev in env_vars)
            servers_code.append(f"        env_vars=[{env_vars_str}],\n")
        
        servers_code.append(f"        description=\"{service.replace('_', ' ').title()} integration\",\n")
        
        # Tools for this server - ONLY filtered tools that belong to this service
        all_server_tools = server.get("tools", [])
        server_tool_names = []
        for t in all_server_tools:
            tool_name = t.get("name") if isinstance(t, dict) else t
            # Only include if this tool was selected in filtering
            if tool_name in filtered_tool_names:
                server_tool_names.append(tool_name)
        
        if server_tool_names:
            tool_names_str = ", ".join(f'"{name}"' for name in server_tool_names)
            servers_code.append(f"        tools=[{tool_names_str}],\n")
        
        servers_code.append(f"    ),\n")
    
    servers_code.append("]\n")
    servers_code.append(f"\nprint(f'‚úÖ Configured {{len(mcp_servers)}} MCP servers')")
    
    cells.append(create_notebook_cell("code", servers_code))
    
    # ==========================================================================
    # Cell 5b: Skill & System Prompt (generated by meta-agent)
    # ==========================================================================
    if condensed_rules:
        cells.append(create_notebook_cell("markdown", [
            "## 5Ô∏è‚É£ System Prompt (Auto-Generated)\n",
            "\n",
            "This system prompt was generated based on your tools. It will be used for training data and at runtime."
        ]))
        
        # Escape the condensed rules for Python string
        escaped_rules = condensed_rules.replace('\\', '\\\\').replace('"""', '\\"\\"\\"')
        
        skill_code = [
            "#@title üìã System Prompt - Click to expand\n",
            "\n",
            "# System prompt for your agent (auto-generated based on tools)\n",
            f'system_prompt = """{escaped_rules}"""\n',
            "\n",
            "print('‚úÖ System prompt loaded')\n",
            f"print(f'   Length: {{len(system_prompt)}} chars (~{{len(system_prompt)//4}} tokens)')"
        ]
        
        cells.append(create_notebook_cell("code", skill_code))
        
        # Add full skill as collapsible reference (optional viewing)
        if full_skill:
            escaped_skill = full_skill.replace('\\', '\\\\').replace('"""', '\\"\\"\\"')
            
            cells.append(create_notebook_cell("markdown", [
                "### üìñ Full Skill Reference (Optional)\n",
                "\n",
                "This detailed skill document shows exact parameter formats. Used for data generation."
            ]))
            
            full_skill_code = [
                "#@title üìñ Full Skill - Click to expand (for reference only)\n",
                "\n",
                "# Full skill document (used internally for training data generation)\n",
                f'full_skill = """{escaped_skill}"""\n',
                "\n",
                f"print(f'‚úÖ Full skill loaded ({{len(full_skill)}} chars)')"
            ]
            
            cells.append(create_notebook_cell("code", full_skill_code))
    
    # ==========================================================================
    # Cell 6: Build Agent
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 6Ô∏è‚É£ Build Your Agent\n" if not condensed_rules else "## 7Ô∏è‚É£ Build Your Agent\n",
        "\n",
        "This will:\n",
        "1. Create synthetic training data using the skill (~5 min)\n",
        "2. Fine-tune the model (~10-15 min on T4 GPU)\n",
        "3. Package everything for download"
    ]))
    
    # Escape problem statement
    escaped_problem = problem_statement.replace('"', '\\"').replace('\n', '\\n')
    
    # Calculate estimated examples
    auto_examples = len(tool_schemas) * 30
    auto_examples = min(int(auto_examples * 1.65), 1500)
    
    # Build code - use skill if available
    build_code = [
        "from onsetlab import AgentBuilder, BuildConfig\n",
        "import os\n",
        "\n",
        "config = BuildConfig(\n",
        "    num_examples=None,         # Auto-calculate based on tool count (~25/tool)\n",
        "    base_model='qwen2.5-3b',   # Base model to fine-tune\n",
        "    epochs=None,               # Auto-adjust based on dataset size\n",
        "    agent_name='my_agent',     # Name for your agent\n",
        "    output_dir='./agent_build',\n",
        "    runtime='both',            # Generate Ollama + Python runtime\n",
        ")\n",
        "\n",
        "builder = AgentBuilder(\n",
        f"    problem_statement=\"\"\"{escaped_problem}\"\"\",\n",
        "    tools=tools,\n",
        "    mcp_servers=mcp_servers,\n",
        "    api_key=os.environ.get('ANTHROPIC_API_KEY') or os.environ.get('OPENAI_API_KEY'),\n",
        "    config=config,\n",
    ]
    
    # Add skill parameters if available
    if condensed_rules:
        build_code.append("    system_prompt=system_prompt,  # Auto-generated system prompt\n")
    if full_skill:
        build_code.append("    skill=full_skill,             # Skill for guided data generation\n")
    
    build_code.extend([
        ")\n",
        "\n",
        "# Build the agent!\n",
        "agent = builder.build()"
    ])
    
    cells.append(create_notebook_cell("code", build_code))
    
    # ==========================================================================
    # Cell 7: Export Agent
    # ==========================================================================
    next_section = "7Ô∏è‚É£" if not condensed_rules else "8Ô∏è‚É£"
    cells.append(create_notebook_cell("markdown", [
        f"## {next_section} Download Your Agent\n",
        "\n",
        "Export and download your agent package:"
    ]))
    
    cells.append(create_notebook_cell("code", [
        "# Export agent as zip file\n",
        "zip_path = agent.export('./my_agent.zip')\n",
        "\n",
        "# Download in Colab\n",
        "from google.colab import files\n",
        "files.download(zip_path)\n",
        "\n",
        "print('üéâ Agent exported! Check your downloads.')"
    ]))
    
    # ==========================================================================
    # Cell 8: Next Steps
    # ==========================================================================
    # Get service names for the instructions
    service_names = []
    for server in mcp_servers:
        service = server.get("service") or server.get("service_id") or server.get("name", "").lower()
        if service:
            service_names.append(service.replace("_", " ").title())
    
    services_list = ", ".join(service_names) if service_names else "your services"
    
    cells.append(create_notebook_cell("markdown", [
        "## üéâ Next Steps\n",
        "\n",
        "Your agent has been built! To run it locally:\n",
        "\n",
        "### 1. Unzip and setup\n",
        "```bash\n",
        "unzip my_agent.zip\n",
        "cd my_agent\n",
        "pip install -r requirements.txt\n",
        "```\n",
        "\n",
        f"### 2. Configure service tokens ({services_list})\n",
        "```bash\n",
        "cp .env.example .env\n",
        "# Edit .env and add your tokens\n",
        "```\n",
        "\n",
        "### 3. Load model and run\n",
        "```bash\n",
        "ollama create my_agent -f Modelfile\n",
        "python agent.py --interactive\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Built with ‚ù§Ô∏è by [OnsetLab](https://onsetlab.app)"
    ]))
    
    # ==========================================================================
    # Create notebook structure
    # ==========================================================================
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {
                "provenance": [],
                "gpuType": "T4"
            },
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
            },
            "language_info": {
                "name": "python"
            },
            "accelerator": "GPU"
        },
        "cells": cells
    }
    
    notebook_json = json.dumps(notebook, indent=2)
    
    print(f"   ‚úÖ Generated notebook with {len(cells)} cells")
    print(f"   üìÑ Notebook size: {len(notebook_json)} chars")
    
    return {
        "colab_notebook": notebook_json,
    }

"""
Generate Notebook Node
======================
Creates the final Colab notebook with all discovered information.
"""

import json
from meta_agent.state import MetaAgentState


# Note: Env var filtering is now done by LLM in generate_guides node.
# The servers passed here should already have cleaned env_vars.
# This is just a simple fallback if somehow unfiltered vars slip through.

def filter_credential_env_vars(env_vars: list) -> list:
    """
    Simple fallback filter for env vars.
    
    Note: Main filtering is done by LLM in generate_guides node.
    This just catches obvious transport/config vars if they slip through.
    """
    if not env_vars:
        return []
    
    # Simple skip list for obvious non-credentials
    SKIP = {"MCP_TRANSPORT", "STREAMABLE_HTTP_PORT", "PORT", "HOST", "DEBUG", "NODE_ENV"}
    
    filtered = [
        ev for ev in env_vars
        if ev.upper() not in SKIP and "_PORT" not in ev.upper()
    ]
    
    return filtered if filtered else env_vars


def create_notebook_cell(cell_type: str, source: list[str], execution_count: int = None) -> dict:
    """Create a Jupyter notebook cell."""
    cell = {
        "cell_type": cell_type,
        "metadata": {},
        "source": source,
    }
    if cell_type == "code":
        cell["execution_count"] = execution_count
        cell["outputs"] = []
    return cell


def generate_notebook(state: MetaAgentState) -> dict:
    """
    Generate the complete Colab notebook.
    
    Notebook includes:
    1. Title and description
    2. Installation cell (pip install onsetlab)
    3. Configuration cell (API keys, tokens)
    4. Tool schemas cell
    5. MCP/API server configs cell
    6. Build cell (builder.build())
    7. Export/download cell
    
    Args:
        state: Current MetaAgentState
        
    Returns:
        State update with colab_notebook JSON string
    """
    problem_statement = state.get("problem_statement", "")
    
    # Use FILTERED results (set by filter_tools node)
    # Fall back to unfiltered if filtered not available
    mcp_servers = state.get("filtered_mcp_servers") or state.get("mcp_servers", [])
    api_servers = state.get("filtered_api_servers") or state.get("api_servers", [])
    tool_schemas = state.get("filtered_tool_schemas") or state.get("tool_schemas", [])
    token_guides = state.get("token_guides", [])
    
    print("\nüìì Generating Colab notebook...")
    
    cells = []
    
    # ==========================================================================
    # Cell 1: Title and Introduction
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "# üöÄ OnsetLab Agent Builder\n",
        "\n",
        "This notebook was auto-generated by the OnsetLab Meta-Agent.\n",
        "\n",
        f"**Problem Statement:** {problem_statement}\n",
        "\n",
        "## What this notebook does:\n",
        f"1. Configures **{len(mcp_servers)}** MCP servers\n",
        f"2. Sets up **{len(api_servers)}** API integrations\n",
        f"3. Registers **{len(tool_schemas)}** tools\n",
        "4. Fine-tunes a small language model\n",
        "5. Packages your agent for local deployment\n",
        "\n",
        "---"
    ]))
    
    # ==========================================================================
    # Cell 2: Installation
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 1Ô∏è‚É£ Install Dependencies\n",
        "\n",
        "First, check GPU and install all required dependencies:"
    ]))
    
    cells.append(create_notebook_cell("code", [
        "# Check GPU\n",
        "!nvidia-smi --query-gpu=name --format=csv,noheader\n",
        "\n",
        "# Install Unsloth (Colab-optimized) for efficient LoRA training\n",
        '!pip install -q "unsloth[colab-new] @ git+https://github.com/unslothai/unsloth.git"\n',
        "\n",
        "# Install training dependencies (--no-deps to avoid version conflicts)\n",
        "!pip install -q --no-deps xformers trl peft accelerate bitsandbytes\n",
        "\n",
        "# Install data generation dependencies\n",
        "!pip install -q openai httpx\n",
        "\n",
        "print('‚úÖ All dependencies installed!')"
    ]))
    
    # ==========================================================================
    # Cell 3: Token Setup Guide
    # ==========================================================================
    if token_guides:
        guide_lines = [
            "## 2Ô∏è‚É£ Setup Authentication Tokens\n",
            "\n",
            "Before running the build, you need to obtain access tokens for each service.\n",
            "\n",
        ]
        
        for guide in token_guides:
            guide_lines.append(f"### {guide['service'].replace('_', ' ').title()}\n")
            guide_lines.append(f"**Auth Type:** {guide['auth_type']}\n")
            
            # Show ALL required env vars
            env_vars = guide.get('env_vars', [guide.get('env_var')])
            if len(env_vars) == 1:
                guide_lines.append(f"**Environment Variable:** `{env_vars[0]}`\n")
            else:
                guide_lines.append(f"**Environment Variables ({len(env_vars)} required):**\n")
                for ev in env_vars:
                    guide_lines.append(f"- `{ev}`\n")
            
            guide_lines.append("\n**Steps:**\n")
            for i, step in enumerate(guide['steps'], 1):
                # Remove existing numbering if present
                step_text = step.lstrip('0123456789. ')
                guide_lines.append(f"{i}. {step_text}\n")
            guide_lines.append("\n---\n\n")
        
        cells.append(create_notebook_cell("markdown", guide_lines))
    
    # ==========================================================================
    # Cell 4: Configuration
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 3Ô∏è‚É£ Configure API Keys & Tokens\n",
        "\n",
        "Enter your API keys and tokens below:"
    ]))
    
    config_lines = [
        "import os\n",
        "\n",
        "# LLM API Key for training data generation (choose ONE)\n",
        "# Option 1: OpenAI (gpt-4o)\n",
        "os.environ['OPENAI_API_KEY'] = ''  # @param {type:\"string\"}\n",
        "# Option 2: Anthropic (claude-sonnet-4.5) - RECOMMENDED for better quality\n",
        "os.environ['ANTHROPIC_API_KEY'] = ''  # @param {type:\"string\"}\n",
        "\n",
    ]
    
    # Add env vars for each MCP server
    if mcp_servers:
        config_lines.append("# --- MCP Server Tokens ---\n")
        for server in mcp_servers:
            service_name = server['service'].replace('_', ' ').title()
            
            # Handle both old (env_var) and new (env_vars) formats
            env_vars = server.get("env_vars") or []
            if not env_vars and server.get("env_var"):
                env_vars = [server.get("env_var")]
            if not env_vars:
                env_vars = [f"{server['service'].upper()}_TOKEN"]
            
            # Filter out non-credential env vars (transport config, ports, etc.)
            env_vars = filter_credential_env_vars(env_vars)
            
            if env_vars:
                config_lines.append(f"# {service_name} - {len(env_vars)} credential(s) required\n")
                for env_var in env_vars:
                    config_lines.append(f"os.environ['{env_var}'] = ''  # @param {{type:\"string\"}}\n")
                config_lines.append("\n")
    
    # Add env vars for each API server (if any)
    if api_servers:
        config_lines.append("# --- API Server Tokens ---\n")
        for api in api_servers:
            env_var = api.get("env_var") or f"{api['service'].upper()}_API_KEY"
            service_name = api['service'].replace('_', ' ').title()
            config_lines.append(f"# {service_name} API Key\n")
            config_lines.append(f"os.environ['{env_var}'] = ''  # @param {{type:\"string\"}}\n")
            config_lines.append("\n")
    
    config_lines.append("print('‚úÖ Configuration set!')")
    
    cells.append(create_notebook_cell("code", config_lines))
    
    # ==========================================================================
    # Cell 5: Tool Schemas
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 4Ô∏è‚É£ Tool Schemas\n",
        "\n",
        f"The following **{len(tool_schemas)}** tools were discovered:"
    ]))
    
    # Format tool schemas as Python code
    tools_code = [
        "from onsetlab import ToolSchema\n",
        "\n",
        "# Discovered tool schemas\n",
        "tools = [\n",
    ]
    
    for tool in tool_schemas:
        tools_code.append(f"    ToolSchema(\n")
        tools_code.append(f"        name=\"{tool.get('name', 'unknown')}\",\n")
        
        # Escape description
        desc = tool.get('description', '').replace('"', '\\"').replace('\n', ' ')[:100]
        tools_code.append(f"        description=\"{desc}\",\n")
        
        # Parameters
        params = tool.get('inputSchema', {}).get('properties', {})
        if params:
            tools_code.append(f"        parameters={json.dumps(params, indent=12)[:-1]}        }},\n")
        else:
            tools_code.append(f"        parameters={{}},\n")
        
        required = tool.get('inputSchema', {}).get('required', [])
        tools_code.append(f"        required_params={required},\n")
        tools_code.append(f"    ),\n")
    
    tools_code.append("]\n")
    tools_code.append(f"\nprint(f'‚úÖ Loaded {{len(tools)}} tools')")
    
    cells.append(create_notebook_cell("code", tools_code))
    
    # ==========================================================================
    # Cell 6: Server Configs
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 5Ô∏è‚É£ Server Configurations\n",
        "\n",
        "MCP servers and API configurations:"
    ]))
    
    servers_code = [
        "from onsetlab import MCPServerConfig\n",
        "\n",
        "# MCP Server configurations\n",
        "mcp_servers = [\n",
    ]
    
    for server in mcp_servers:
        servers_code.append(f"    MCPServerConfig(\n")
        servers_code.append(f"        package=\"{server.get('package', '')}\",\n")
        
        # Include server_type (npm, docker, go, etc.)
        server_type = server.get('server_type', 'npm')
        if server_type != 'npm':
            servers_code.append(f"        server_type=\"{server_type}\",\n")
        
        servers_code.append(f"        auth_type=\"{server.get('auth_type', 'none')}\",\n")
        
        # Handle both old (env_var) and new (env_vars) formats
        env_vars = server.get("env_vars") or []
        if not env_vars and server.get("env_var"):
            env_vars = [server.get("env_var")]
        
        # Filter out transport/config vars - only keep actual credentials
        env_vars = filter_credential_env_vars(env_vars)
        
        if env_vars:
            # Pass only CREDENTIAL env vars (filtered)
            env_vars_str = ", ".join(f'"{ev}"' for ev in env_vars)
            servers_code.append(f"        env_vars=[{env_vars_str}],\n")
        
        servers_code.append(f"        description=\"{server.get('service', '').replace('_', ' ').title()} integration\",\n")
        if server.get('setup_url'):
            servers_code.append(f"        setup_url=\"{server['setup_url']}\",\n")
        
        # Include Docker image for non-npm servers
        docker_image = server.get('docker_image')
        if docker_image:
            servers_code.append(f"        docker_image=\"{docker_image}\",\n")
        
        # Include tools for this server
        server_tools = server.get('tools', [])
        if server_tools:
            tool_names = [t.get('name', t) if isinstance(t, dict) else t for t in server_tools]
            tool_names_str = ", ".join(f'"{name}"' for name in tool_names)
            servers_code.append(f"        tools=[{tool_names_str}],\n")
        
        servers_code.append(f"    ),\n")
    
    servers_code.append("]\n")
    
    servers_code.append(f"\nprint(f'‚úÖ Configured {{len(mcp_servers)}} MCP servers')")
    
    cells.append(create_notebook_cell("code", servers_code))
    
    # ==========================================================================
    # Cell 6b: API Server Configurations (if any)
    # ==========================================================================
    if api_servers:
        cells.append(create_notebook_cell("markdown", [
            "## 5Ô∏è‚É£b API Server Configurations\n",
            "\n",
            f"The following **{len(api_servers)}** services need API implementation (no MCP server found):\n",
            "\n",
            "These endpoints will be auto-generated as `api_tools.py` in the agent package.\n"
        ]))
        
        api_code = [
            "from onsetlab import APIServerConfig, APIToolSchema\n",
            "\n",
            "# API Server configurations (for services without MCP)\n",
            "# OnsetLab will generate api_tools.py with HTTP client code\n",
            "\n",
            "api_servers = [\n",
        ]
        
        for api in api_servers:
            service_name = api.get('service', 'api')
            base_url = api.get('base_url', '')
            auth_type = api.get('auth_type', 'bearer')
            auth_header = api.get('auth_header', '')
            env_var = api.get('env_var', f"{service_name.upper()}_API_KEY")
            api_docs_url = api.get('api_docs_url', '')
            
            api_code.append(f"    APIServerConfig(\n")
            api_code.append(f"        name='{service_name}',\n")
            api_code.append(f"        base_url='{base_url}',\n")
            api_code.append(f"        auth_type='{auth_type}',\n")
            api_code.append(f"        auth_env_var='{env_var}',\n")
            if auth_header:
                # Extract header name from format like "Authorization: Bearer {token}"
                header_name = auth_header.split(':')[0] if ':' in auth_header else auth_header
                api_code.append(f"        auth_header='{header_name}',\n")
            if api_docs_url:
                api_code.append(f"        setup_url='{api_docs_url}',\n")
            api_code.append(f"        description='{service_name.replace('_', ' ').title()} API integration',\n")
            
            # Add endpoints as APIToolSchema
            endpoints = api.get('endpoints', [])
            api_code.append(f"        tools=[\n")
            for ep in endpoints[:10]:  # Limit to 10 endpoints per service
                desc = ep.get('description', '').replace("'", "\\'").replace('\n', ' ')[:80]
                api_code.append(f"            APIToolSchema(\n")
                api_code.append(f"                name='{ep.get('name', 'unknown')}',\n")
                api_code.append(f"                method='{ep.get('method', 'GET')}',\n")
                api_code.append(f"                path='{ep.get('path', '/')}',\n")
                api_code.append(f"                description='{desc}',\n")
                api_code.append(f"                parameters={json.dumps(ep.get('parameters', {}))},\n")
                api_code.append(f"                required_params={ep.get('required_params', [])},\n")
                if ep.get('request_body'):
                    api_code.append(f"                request_body_schema={json.dumps(ep['request_body'])},\n")
                api_code.append(f"            ),\n")
            if len(endpoints) > 10:
                api_code.append(f"            # ... and {len(endpoints) - 10} more endpoints\n")
            api_code.append(f"        ],\n")
            api_code.append(f"    ),\n")
        
        api_code.append("]\n")
        api_code.append(f"\nprint(f'‚úÖ Configured {{len(api_servers)}} API servers')")
        
        cells.append(create_notebook_cell("code", api_code))
    
    # ==========================================================================
    # Cell 7: Build Agent
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 6Ô∏è‚É£ Build Your Agent\n",
        "\n",
        "Now let's build the agent! This will:\n",
        "1. Generate a system prompt\n",
        "2. Create synthetic training data\n",
        "3. Fine-tune the model (~15 min on T4 GPU)\n",
        "4. Package the agent for deployment"
    ]))
    
    # Escape problem statement for Python string
    escaped_problem = problem_statement.replace('"', '\\"').replace('\n', '\\n')
    
    # Determine if we have API servers
    has_api = len(api_servers) > 0
    
    # Calculate optimal examples based on tool count
    auto_examples = len(tool_schemas) * 30  # ~30 per tool, will be calculated by builder
    auto_examples = min(int(auto_examples * 1.65), 1500)  # Cap at 1500
    
    build_code = [
        "from onsetlab import AgentBuilder, BuildConfig\n",
        "\n",
        "# Build configuration\n",
        f"# Auto-calculated: ~{auto_examples} examples for {len(tool_schemas)} tools\n",
        "config = BuildConfig(\n",
        "    num_examples=None,         # Auto-calculate based on tool count\n",
        "    batch_size=10,             # Examples per API call\n",
        "    base_model='qwen2.5-3b',   # Base model to fine-tune\n",
        "    epochs=3,                  # Training epochs\n",
        "    agent_name='my_agent',     # Name for your agent\n",
        "    runtime='both',            # Generate Ollama + Python runtime\n",
        "    use_llm_for_prompt=True,   # Use LLM for comprehensive system prompt\n",
        ")\n",
        "\n",
        "# Create builder\n",
        "builder = AgentBuilder(\n",
        f"    problem_statement=\"\"\"{escaped_problem}\"\"\",\n",
        "    tools=tools,\n",
        "    mcp_servers=mcp_servers,\n",
    ]
    
    # Add api_servers only if present
    if has_api:
        build_code.append("    api_servers=api_servers,  # API fallback services\n")
    
    build_code.extend([
        "    api_key=os.environ.get('ANTHROPIC_API_KEY') or os.environ.get('OPENAI_API_KEY'),\n",
        "    config=config,\n",
        ")\n",
        "\n",
        "# Build the agent!\n",
        "agent = builder.build()"
    ])
    
    cells.append(create_notebook_cell("code", build_code))
    
    # ==========================================================================
    # Cell 8: Export Agent
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## 7Ô∏è‚É£ Download Your Agent\n",
        "\n",
        "Export and download your agent package:"
    ]))
    
    cells.append(create_notebook_cell("code", [
        "# Export agent as zip file\n",
        "zip_path = agent.export('./my_agent.zip')\n",
        "\n",
        "# Download in Colab\n",
        "from google.colab import files\n",
        "files.download(zip_path)\n",
        "\n",
        "print('üéâ Agent exported! Check your downloads.')"
    ]))
    
    # ==========================================================================
    # Cell 9: Next Steps
    # ==========================================================================
    cells.append(create_notebook_cell("markdown", [
        "## üéâ Next Steps\n",
        "\n",
        "Your agent has been built! To run it locally:\n",
        "\n",
        "```bash\n",
        "# Unzip the agent\n",
        "unzip my_agent.zip\n",
        "cd my_agent\n",
        "\n",
        "# Install dependencies\n",
        "pip install -r requirements.txt\n",
        "\n",
        "# Load the model in Ollama\n",
        "ollama create my_agent -f Modelfile\n",
        "\n",
        "# Run the agent\n",
        "python agent.py\n",
        "```\n",
        "\n",
        "---\n",
        "\n",
        "Built with ‚ù§Ô∏è by [OnsetLab](https://onsetlab.app)"
    ]))
    
    # ==========================================================================
    # Create notebook structure
    # ==========================================================================
    notebook = {
        "nbformat": 4,
        "nbformat_minor": 0,
        "metadata": {
            "colab": {
                "provenance": [],
                "gpuType": "T4"
            },
            "kernelspec": {
                "name": "python3",
                "display_name": "Python 3"
            },
            "language_info": {
                "name": "python"
            },
            "accelerator": "GPU"
        },
        "cells": cells
    }
    
    notebook_json = json.dumps(notebook, indent=2)
    
    print(f"   ‚úÖ Generated notebook with {len(cells)} cells")
    print(f"   üìÑ Notebook size: {len(notebook_json)} chars")
    
    return {
        "colab_notebook": notebook_json,
    }
